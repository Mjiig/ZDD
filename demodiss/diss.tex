% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{amssymb}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Angus Hammond}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{Representing Solutions to the Travelling Salesman Problem Using Zero Suppressed Binary Decision Diagrams} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Corpus Christi College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Angus Hammond                       \\
College:            & \bf Corpus Christi College                     \\
Project Title:      & \bf Representing Solutions to the Travelling Salesman Problem Using Zero Suppressed Binary Decision Diagrams \\
Examination:        & \bf Computer Science Tripos -- Part II, July 2017  \\
Word Count:         & \bf ????  \\
Project Originator: & Angus Hammond                    \\
Supervisor:         & Dr Timothy Griffin                    \\ 
\end{tabular}
}
\stepcounter{footnote}


\section*{Original Aims of the Project}

To build an implementation of Zero Suppressed Binary Decision Diagrams (ZDDs), and a solver for the Travelling Salesman Problem (TSP) that makes use of them to represent possible solutions. The performance of this solver was then compared to that of a standard dynamic programming solution to the same problem, with the intention to show that both had the same asymptotic complexity. 


\section*{Work Completed}

An python package implementing ZDDs, as well as a number of standard logical operators on them has been implemented and tested. A TSP solver built on this package has been built, along with a solver using a dynamic programming algorithm and a brute force solver (for correctness verification). In order to measure the performance of these solvers, a framework for generating random instance of TSP has been built, and the performance of all of the solvers on these instances has been measured.

\section*{Special Difficulties}

A mistaken assumption about how operations that can be used to encode negation behave on ZDDs (due to a substantial difference to the behaviour of traditional BDDs), led to a significant delay in completing the correct implementation of the implication and negation operators, which are essential for this project.
 
\newpage
\section*{Declaration}

I, Angus Hammond of Corpus Christi College, being a candidate for Part II of the Computer
Science Tripos, hereby declare
that this dissertation and the work described in it are my own work,
unaided except as may be specified below, and that the dissertation
does not contain material that has already been used to any substantial
extent for a comparable purpose.

\bigskip
\leftline{Signed [signature]}

\medskip
\leftline{Date [date]}

\tableofcontents

\listoffigures

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}
\section{Project Outline}
This project seeks to demonstrate an equivalence between two different algorithms for solving the Travelling Salesman Problem, an obvious dynamic programming solution, and a solution based on techniques from logic theory that represents all Hamiltonian paths of a graph and enumerates them in a structured way. The second algorithm represents Hamiltonian paths of a graph as a constrained set of propositional variables and stores the set of satisfying assignments using a data structure called a Zero-suppressed Binary Decision Diagram (ZDD). This data structure is a variant of the better known Binary Decision Diagram (BDD). The theoretical basis for believing this equivalence exists, an explanation of the origins and working of ZDDs and descriptions of both of the algorithms are included in the Preparation chapter.

The majority of the code I have written as part of this project is a library in Python for building and manipulating ZDDs efficiently, including support for producing a new ZDD from a previously built one using several standard propositional operations (for example negation, conjunction, disjunction and implication). In addition I have implemented both of the algorithms being reviewed, along with a third simpler algorithm for the Travelling Salesman Problem to help verify the correctness of both implementations. In order to test all of the implementations I have written two procedures to generate instances of the Travelling Salesman Problem, one of which produces problem instances with analytically verifiable solutions, to further aid verification of the correctness of all the algorithms, with the other producing more general problem instances in order to demonstrate the generality of all the algorithms. How each of these components is implemented is described in more detail in the Implementation chapter.

In order to experimentally demonstrate the equivalence of the two algorithms I have run them on a large number of automatically generated instances of the Travelling Salesman Problem and measured both the average time and average number of logical operations taken by the two algorithms to produce a solution, as a function of the number of cities in the problem. In both cases the function is expected to have the form $\Theta(2^nn^2)$.

\chapter{Preparation}

\section{The Travelling Salesman Problem}
The Travelling Salesman Problem exists as both a function problem and a decision problem. In this project I have focused on the function problem, but it is trivial to construct a program solving the decision problem given a program solving the function problem. The problem is to find the lowest cost path that visits all of a set of cities. More formally, given a set of cities $C$ and a cost function $f: C\to\mathbb{R}$ find the minimum possible value of $\sum_{i=1}^{|C|-1}f(x_i,x_{i+1})$ where each $x_i$ has been assigned a distinct value from $C$.

The related decision problem takes a target distance as well as a set of cities and a cost function, and is only required to evaluate whether there is a path with total cost less than the given target distance. This form of the problem is known to be NP-Complete.

Variants of the problem exist, for example requiring that the path start and finish in the same city, not guaranteeing that the the cost function be total (i.e.\ prohibiting certain cities from being visited consecutively) or guaranteeing that the cost function will only take integer values. Most such variant are easy to reduce to an instance of the described function problem.

\section{Solving The Travelling Salesman Problem with Dynamic Programming}
An entirely naive brute force approach to the Traveling Salesman Problem takes $\Theta(n!)$ time to run. This can be improved on significantly with dynamic programming. Let the $C$ be the set of cities and $f$ be the cost function. Define $g(S, c)$, where $S\subseteq C$ and $c\in S$ to be the lowest possible cost of a path that starts in $c$ and visits all the cities in $S$. Computing $g({c}, c)$ for all $c\in C$ is trivial, since paths containing only a single city have a cost of zero. Then for all other values of $S\subseteq C$, compute $g(S,c)$ as 

$$
g(S,c)=\min_{c'\in S\setminus\{c\}}(g(S\setminus\{c\},c') + f(c,c'))
$$

Once all values of $g$ have been computed, the solution to the problem is given by

$$
\min_{c\in C} g(C,c)
$$

If $C$ has size $n$ there are $2^n$ subsets of $C$, so $n2^n$ possible sets of arguments to $g$, each of which requires evaluation of up to $n$ terms to compute, this algorithm has a time complexity of at most $\mathcal{O}(n^22^n)$.

\section{Binary Decision Diagrams}
The general principle of a Binary Decision Diagram (BDD) is to give a canonical graph based representation of boolean functions (or equivalently, sentences of propositional logic). The most trivial way to achieve this is with a binary decision tree, in which we take a rooted tree, every internal node of which has two children and is labelled with one of the inputs to the function being represented. Every node on the same layer of the tree should be labelled with the same input, and a path from root to leaf should contain exactly one node labelled with each variable.

If we label the arcs from each node to its children $T$ and $F$, and say that following an arc labelled $T$ from a node labelled $p$ corresponds to assuming that $p$ is true, and vice versa for $F$, we now have a tree in which every possible assignment of inputs to the function being represented corresponds to a unique path from the root to a leaf of the tree. We can represent the value of the function given these inputs by labelling the leaf node $1$ or $0$ for true and false respectively. Figure \ref{decisiontree} is an example of such a tree representing the function $p\wedge\neg q$.

\begin{figure}[tbh]
\centerline{\includegraphics{figs/decisiontree.pdf}}
\caption{A binary decision tree representing the function $p\wedge\neg q$. Conventionally, the $T$ arc out of a node is drawn with a solid line, and the $F$ arc with a dotted line.}
\label{decisiontree}
\end{figure}

Although this representation is easy to understand, storing it in memory is obviously extremely inefficient. An obvious initial optimization is to avoid storing multiple redundant subtrees, resulting in a directed acyclic graph, as shown in Figure \ref{basicdiagram}.

\begin{figure}[tbh]
\centerline{\includegraphics{figs/basicdiagram.pdf}}
\caption{A graph representing $p\wedge\neg q$ generated by sharing of redundant subtrees in Figure \ref{decisiontree}}
\label{basicdiagram}
\end{figure}

This form is obviously not minimal however, since each node is explicitly labelled with a variable name, which could be calculated from the depth of the node within the (now implicit) tree. Instead of removing the node labels, we can instead exploit them to remove sections of the graph without loss of information. In a typical BDD, nodes are removed if both of their children are the same (ie, if the value of the relevant variable has no effect on the output of the function given the already specified variables). Figure \ref{bdd} gives an example of such a diagram. In a ZDD, nodes are instead removed if their $T$ child is the $0$ node (hence, \emph{zero suppressed}). This produces the smallest representation of $p\wedge\neg q$ of all the techniques presented, as shown in Figure \ref{zdd}.

\begin{figure}[tbh]
\centerline{\includegraphics{figs/bdd.pdf}}
\caption{$p\wedge\neg q$ represented using a typical BDD.}
\label{bdd}
\end{figure}

\begin{figure}[tbh]
\centerline{\includegraphics{figs/zdd.pdf}}
\caption{$p\wedge\neg q$ represented using a ZDD. Notice it contains one fewer node and two fewer edges than the equivalent BDD.}
\label{zdd}
\end{figure}

\section{Documentation}
The course notes for the Cambridge Computer Science 1B course on Logic \& Proof contain a detailed description of how BDDs can be constructed and combined. The general form of the recursive algorithm described for combining two BDDs is the same for ZDDs, and is described in more detail in the Implementation section.

The use of ZDDs for solving combinatoric problems is covered in Volume 4A of Donald Knuth's \emph{The Art Of Computer Science}, along with extensive analysis of their time and memory complexity.

\chapter{Implementation}

\chapter{Evaluation}


\chapter{Conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

\chapter{Project Proposal}

\input{proposal}

\end{document}
