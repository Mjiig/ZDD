% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[labelformat=simple]{subcaption}

\renewcommand\thesubfigure{(\alph{subfigure})}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Angus Hammond}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{Representing Solutions to the Travelling Salesman Problem Using Zero Suppressed Binary Decision Diagrams} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Corpus Christi College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Angus Hammond                       \\
College:            & \bf Corpus Christi College                     \\
Project Title:      & \bf Representing Solutions to the Travelling Salesman Problem Using Zero Suppressed Binary Decision Diagrams \\
Examination:        & \bf Computer Science Tripos -- Part II, July 2017  \\
Word Count:         & \bf ????  \\
Project Originator: & Angus Hammond                    \\
Supervisor:         & Dr Timothy Griffin                    \\ 
\end{tabular}
}
\stepcounter{footnote}


\section*{Original Aims of the Project}

To build an implementation of Zero Suppressed Binary Decision Diagrams (ZDDs), and a solver for the Travelling Salesman Problem (TSP) that makes use of them to represent possible solutions. The performance of this solver was then compared to that of a standard dynamic programming solution to the same problem, with the intention to show that both had the same asymptotic complexity. 


\section*{Work Completed}

An python package implementing ZDDs, as well as a number of standard logical operators on them has been implemented and tested. A TSP solver built on this package has been built, along with a solver using a dynamic programming algorithm and a brute force solver (for correctness verification). In order to measure the performance of these solvers, a framework for generating random instance of TSP has been built, and the performance of all of the solvers on these instances has been measured.

\section*{Special Difficulties}

A mistaken assumption about how operations that can be used to encode negation behave on ZDDs (due to a substantial difference to the behaviour of traditional BDDs), led to a significant delay in completing the correct implementation of the implication and negation operators, which are essential for this project.
 
\newpage
\section*{Declaration}

I, Angus Hammond of Corpus Christi College, being a candidate for Part II of the Computer
Science Tripos, hereby declare
that this dissertation and the work described in it are my own work,
unaided except as may be specified below, and that the dissertation
does not contain material that has already been used to any substantial
extent for a comparable purpose.

\bigskip
\leftline{Signed [signature]}

\medskip
\leftline{Date [date]}

\tableofcontents

\listoffigures

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}
\section{Project Outline}
This project seeks to demonstrate an equivalence between two different algorithms for solving the Travelling Salesman Problem, an obvious dynamic programming solution, and a solution based on techniques from logic theory that represents all Hamiltonian paths of a graph and enumerates them in a structured way. The second algorithm represents Hamiltonian paths of a graph as a constrained set of propositional variables and stores the set of satisfying assignments using a data structure called a Zero-suppressed Binary Decision Diagram (ZDD). This data structure is a variant of the better known Binary Decision Diagram (BDD). The theoretical basis for believing this equivalence exists, an explanation of the origins and working of ZDDs and descriptions of both of the algorithms are included in the Preparation chapter.

The majority of the code I have written as part of this project is a library in Python for building and manipulating ZDDs efficiently, including support for producing a new ZDD from a previously built one using several standard propositional operations (for example negation, conjunction, disjunction and implication). In addition I have implemented both of the algorithms being reviewed, along with a third simpler algorithm for the Travelling Salesman Problem to help verify the correctness of both implementations. In order to test all of the implementations I have written two procedures to generate instances of the Travelling Salesman Problem, one of which produces problem instances with analytically verifiable solutions, to further aid verification of the correctness of all the algorithms, with the other producing more general problem instances in order to demonstrate the generality of all the algorithms. How each of these components is implemented is described in more detail in the Implementation chapter.

In order to experimentally demonstrate the equivalence of the two algorithms I have run them on a large number of automatically generated instances of the Travelling Salesman Problem and measured both the average time and average number of logical operations taken by the two algorithms to produce a solution, as a function of the number of cities in the problem. In both cases the function is expected to have the form $\Theta(2^nn^2)$.

\chapter{Preparation}

\section{The Travelling Salesman Problem}
The Travelling Salesman Problem exists as both a function problem and a decision problem. In this project I have focused on the function problem, but it is trivial to construct a program solving the decision problem given a program solving the function problem. The problem is to find the lowest cost path that visits all of a set of cities. More formally, given a set of cities $C$ and a cost function $f: C\to\mathbb{R}$ find the minimum possible value of $\sum_{i=1}^{|C|-1}f(x_i,x_{i+1})$ where each $x_i$ has been assigned a distinct value from $C$.

The related decision problem takes a target distance as well as a set of cities and a cost function, and is only required to evaluate whether there is a path with total cost less than the given target distance. This form of the problem is known to be NP-Complete.

Variants of the problem exist, for example requiring that the path start and finish in the same city, not guaranteeing that the the cost function be total (i.e.\ prohibiting certain cities from being visited consecutively) or guaranteeing that the cost function will only take integer values. Most such variant are easy to reduce to an instance of the described function problem.

\section{Solving The Travelling Salesman Problem with Dynamic Programming} \label{dynamicprogramming}
An entirely naive brute force approach to the Travelling Salesman Problem takes $\Theta(n!)$ time to run. This can be improved on significantly with dynamic programming. Let the $C$ be the set of cities and $f$ be the cost function. Define $g(S, c)$, where $S\subseteq C$ and $c\in S$ to be the lowest possible cost of a path that starts in $c$ and visits all the cities in $S$. Computing $g({c}, c)$ for all $c\in C$ is trivial, since paths containing only a single city have a cost of zero. Then for all other values of $S\subseteq C$, compute $g(S,c)$ as 

$$
g(S,c)=\min_{c'\in S\setminus\{c\}}(g(S\setminus\{c\},c') + f(c,c'))
$$

Once all values of $g$ have been computed, the solution to the problem is given by

$$
\min_{c\in C} g(C,c)
$$

If $C$ has size $n$ there are $2^n$ subsets of $C$, so $n2^n$ possible sets of arguments to $g$, each of which requires evaluation of up to $n$ terms to compute, this algorithm has a time complexity of at most $\mathcal{O}(n^22^n)$.

\section{Hamiltonian Paths as Propositional Sentences} \label{hamiltonianpath}
An alternative approach to solving the Travelling Salesman Problem is to attempt to enumerate all of the Hamiltonian paths through the complete graph that represents each city as a node. For each Hamiltonian path we calculate the cost of the path it represents and return the lowest observed value. Although the Hamiltonian paths through a complete graph are easy to generate directly, doing so leads to a very slow algorithm for the Travelling Salesman Problem ($\Theta(n!)$). Instead we represent the set of Hamiltonian paths using a constrained set of propositional variables, which will subsequently allow us to enumerate them in a more structured way.

Given a set $C$ of cities, define a set of variables $visited_{c,i}$ for all $c\in C$ and $1\leq i\leq|C|$. An assignment to this set of variables is interpreted as encoding a path that visits city $c$ as the $i$th city in the path if and only if $visited_{c,i}$ is true. In order to ensure that only assignments corresponding to valid Hamiltonian paths are possible the following constraints can be imposed:

\begin{gather*}
visited_{c,i}\implies\bigwedge_{c'\in C\setminus c}\neg visited_{c',i} \\ \\
visited_{c,i}\implies\bigwedge_{1\leq i'\leq |C|,i'\neq i}\neg visited_{c,i'} \\ \\
\bigwedge_{c\in C}\bigvee_{1\leq i\leq |C|} visited_{c,i}
\end{gather*}

Intuitively speaking, the first constraint requires that at most a single city is visited at a time, the second constraint requires that each city is visited at most once and the third constraint requires that every city is visited at some point. Since the number of cities to visit and the number of opportunities for the path to visit a city are exactly equal, this implies the constraint that a city is visited at every step. In order to enumerate Hamiltonian paths of an arbitrary graph, additional constraints could be added requiring that when a given city is visited at a given point along the path a city which is connected to it by an arc in the graph is visited at the next point in the path. However in the special case I have considered in this project of representing Hamiltonian paths only in order to solve the Travelling Salesman Problem this is unnecessary because the graph of connected cities is generally complete.

\section{Binary Decision Diagrams}
Since all permutations of the nodes are Hamiltonian paths of a complete graph, there will be $n!$ possible Hamiltonian paths. Therefore in order to use an algorithm based on enumerating them to solve the Travelling Salesman Problem it is necessary to find an algorithm for propositional satisfiability that enumerates satisfying assignments in a structured way, so that computations can be shared between them. To achieve this I have used ZDDs, which are a type of decision diagram designed to most efficiently represent the satisfying assignments for a set of propositional constraints when there are few satisfying assignments and few asserted propositional letters in the satisfying assignments.

The simplest data structure in the family of decision diagrams is a binary decision tree, which represents propositional sentences as a rooted tree in which internal nodes are labelled with propositional letters and leaves are labelled with $0$ or $1$. Every node at the same level of the tree is labelled with the same propositional letter, so that all paths from the root of the tree to a leaf pass through exactly one node labelled with each propositional letter, and every such path passes through nodes labelled with the propositional letters in the same order. Each internal node has exactly two children, connected to it by arcs labelled $T$ and $F$. A path from the root to a leaf of the tree corresponds to an assignment, where a propositional letter is asserted in the corresponding assignment if and only if the path follows the arc labelled $T$ out of a node labelled with the propositional letter (and therefore not asserted if and only if the path follows the arc labelled $F$ out of a node labelled with it). Since leaf nodes obviously correspond to paths in a rooted tree, assignments to the propositional letters also correspond to leaf nodes of the tree. Therefore we can use a tree to represent a propositional sentence by labelling a leaf node $1$ if the assignment to the propositional letters is corresponds to satisfies the propositional constraints, and label a leaf node $0$ otherwise.

Binary decision trees give a canonical representation of propositional sentences, in that two propositional sentences are represented by the same binary decision tree if and only if they have the exact same set of satisfying assignments. An example of a a binary decision tree is shown in Figure \ref{decisiontree} which represents the propositional sentence, 

$$
(p\wedge\neg q\wedge\neg r) \vee (\neg p\wedge q\wedge r) \vee (\neg p\wedge\neg q\wedge\neg r)
$$

shown in full disjunctive normal form as each conjunctive clause corresponds to a path from the root of the tree to a leaf labelled $1$, called a $1$-path. In the shown diagram, arcs labelled $T$ are represented by solid lines, and arcs labelled $F$ are represented by dashed lines, which is a standard notation that I will use for all types of decision diagram.

\begin{figure}[tbh]
\centering
\includegraphics{{figs/tree.dot}.pdf}
\caption{A binary decision tree representing a propositional sentence with three satisfying assignments. Solid lines represent arcs labelled $T$, dashed lines represent arcs labelled $F$, internal nodes are elliptical and labelled with propositional letters and leaf nodes are square and labelled with either $1$ or $0$.}
\label{decisiontree}
\end{figure}

It is immediately obvious that binary decision trees are not an efficient method of representing boolean functions and propositional sentences, due to the high degree of redundancy in the produced tree. The storage requirements of such a data structure can immediately be significantly reduced by using a directed acyclic graph instead of a tree, and having identical subtrees of a graph be shared so that only a single copy needs to be stored. Since there are only two possible distinct leaf nodes, and with $n$ propositional letters the binary decision tree has $2^n$ leaf nodes, this saves at least $2^n-2$ nodes just on the last layer of the tree, but in practice can often also save many more on higher layers, especially if the propositional constraints are known to have some structure. Figure \ref{decisiondiagram} shows a representation in this form of the same propositional sentence as represented in Figure \ref{decisiontree}.

In the shown example the sharing of identical subtrees has reduced the total number of nodes to be stored by seven out of a total of fifteen. Despite this, any algorithm operating recursively on the diagram, that is at any point only able to observe a single node and carry out some operation on one or both of its child nodes will observe the exact same structure in both the tree and the directed acyclic graph.

\begin{figure}[tbh]
\centering
\includegraphics{{figs/diagram.dot}.pdf}
\caption{A decision diagram representing the same propositional sentence as Figure \ref{decisiontree} but with all identical subtrees deduplicated. The same conventions on arcs and node shapes are used.}
\label{decisiondiagram}
\end{figure}

However the shown decision diagram is still not maximally efficient, since every internal node is explicitly labelled with a propositional letter but it is possible determine the correct propositional letter based just on the depth of the node within the diagram. Instead of removing the labels and calculating them dynamically, binary decision diagrams (BDDs) use the labels to permit further compression of the graph. The most common compression strategy used is to omit any nodes which have $T$ and $F$ arcs out of them pointing to the same child node. A schematic representation of this compression strategy is shown in Figure \ref{bddcompression}. Compressing the decision diagram shown in \ref{decisiondiagram} in this way results in the diagram shown in \ref{bdd}, which decreases the number of stored nodes further by one.

\begin{figure}[tbh]
\centering

\begin{subfigure}[b]{0.49\textwidth}
\centering
\includegraphics{{figs/bddprecompression.dot}.pdf}
\caption{}
\label{bddprecompression}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
\centering
\includegraphics{{figs/bddpostcompression.dot}.pdf}
\caption{}
\label{bddpostcompression}
\end{subfigure}

\caption{A schematic representation of BDD compression. Any part of a decision diagram that matches the pattern in \subref{bddprecompression} (where the box labelled BDD is any diagram) is replaced by \subref{bddpostcompression} (with the box replaced by whatever value it had in \subref{bddprecompression}).}
\label{bddcompression}
\end{figure}

\begin{figure}[tbh]
\centering
\includegraphics{{figs/bdd.dot}.pdf}
\caption{A BDD produced by applying a standard compression strategy to the diagram shown in Figure \ref{decisiondiagram}.}
\label{bdd}
\end{figure}

\section{Zero-Suppressed Binary Decision Diagrams}
Zero-Suppressed Binary Decision Diagrams (ZDDs) are binary decision diagrams that have been compressed using an alternative strategy. Nodes are omitted, and replaced by the node on their $F$ arc, if their $T$ arc points to a leaf node labelled $0$. This is intended to minimise the size of the decision diagram that needs to be stored particularly when the propositional sentence being represented is sparse, where "sparse" means that the propositional sentence has few satisfying assignments, and those satisfying assignments have few asserted variables. A schematic representation of this compression strategy is shown in Figure \ref{zddcompression}. If the diagram shown in Figure \ref{decisiondiagram} is instead compressed using this strategy, the resulting diagram is the one shown in Figure \ref{zdd}. Storing this diagram in memory requires three fewer nodes than the uncompressed decision diagram and two fewer than the BDD compression strategy. 

\begin{figure}[tbh]
\centering

\begin{subfigure}[b]{0.49\textwidth}
\centering
\includegraphics{{figs/zddprecompression.dot}.pdf}
\caption{}
\label{zddprecompression}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
\centering
\includegraphics{{figs/zddpostcompression.dot}.pdf}
\caption{}
\label{zddpostcompression}
\end{subfigure}

\caption{A schematic representation of ZDD compression. Any part of a decision diagram that matches the pattern in \subref{zddprecompression} (where the box labelled ZDD is any part of the diagram) is replaced by \subref{zddpostcompression} (with the box replaced by whatever value it had in \subref{zddprecompression}).}
\label{zddcompression}
\end{figure}

\begin{figure}[tbh]
\centering
\includegraphics{{figs/zdd.dot}.pdf}
\caption{A ZDD produced by applying the ZDD compression strategy to the diagram shown in Figure \ref{decisiondiagram}.}
\label{zdd}
\end{figure}

\section{Equivalence}
Building a ZDD corresponding to the set of constraints mentioned in Section \ref{hamiltonianpath} and recursively computing the minimum distance path encoded by every subtree results in an algorithm for solving the travelling salesman problem that I expect to be equivalent to the dynamic programming solution described in Section \ref{dynamicprogramming}. I expect this to be true because the section of the graph below any given node corresponds to the set of possible paths for a particular set of nodes still to visit. This is the same set of values computed directly by the dynamic programming solution. The purpose of this project is to verify experimentally that both algorithms have the same run time complexity.

\chapter{Implementation}

\section{Technology Used}
All the code written for this project, the largest part of which is my implementation of a library for manipulating ZDDs, has been written in Python. A significant benefit of python is its native support for fast dictionaries, backed by hash maps, which I have used in several places throughout the library to cache the output of operations so they are not repeatedly recomputed and to reuse previously generated graph nodes whenever possible.  The \textit{dot} language for graph representation is used to allow ZDDs to be exported in a form which can be rendered easily using standard tools provided by the Graphviz package. This was useful both for debugging issues with the library and understanding the structure of the graphs produced by various sets of constraints, so that programs operating on them could be written.

\chapter{Evaluation}

\chapter{Conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

\chapter{Project Proposal}

\input{proposal}

\end{document}
